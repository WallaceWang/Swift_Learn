/*:
 [Previous page](@previous)

 # 总结
 
 在本书中，针对同一个简单的集合类型，我们已经讨论了七种不同的实现方法。每次我们创建一种新的解决方案，我们的代码就变得比之前复杂一些，但是作为交换，我们获取了可观的性能提升。也许用性能测试图表中随着插入实现的进展而稳步下降的曲线最能说明这一点。
 
 ![图 8.1: 对比五种 `SortedSet` 实现的插入性能与 `Array.sort` 的每个元素的平摊开销。](Images/InsertionSummary.png)
 
 我们还有可能实现一个更快的 `SortedSet.insert` 吗？毫无疑问，`BTree3` 还有一些额外的空间可以进行小幅优化；我想 5-10% 改善完全不是问题。如果我们投入更多努力，甚至有可能可以得到 20% 的提升。
 
 那是否还存在可以给我们带来 200-400% 的巨大性能跳跃的优化手段，而我们又恰恰错过了这些很巧妙的方法呢？我相信答案是没有。
 
 首先要注意，当我们将一系列元素插入到一个有序集合中时，我们实际上是在对它们进行排序。我们可以简单地调用 `Array.sort` 来做这件事，这个函数使用了超级快的[内省排序][Introsort]算法。在上面的图表中，最后一行描述的就是 `Array.sort` 在每一个元素上所花费的平摊时间。毫无疑问，`Array.sort` 为我们能够想到的所有有序集合设定了一个性能上限。
 
 [Introsort]: http://www.cs.rpi.edu/~musser/gp/introsort.ps
 
 在一般尺寸的集合中，通过调用 `BTree3.insert` 来进行元素排序相较于 `Array.sort` **仅仅只慢 3.5 倍**。这个结果简直接近的**让人惊讶**！要知道 `BTree3` 的性能测试是针对每个元素单独处理的，而且每次插入后所有存在的元素依然要保持有序。对于 `BTree3.insert` 能够在如此不利的条件下还能表现地这么接近，我真是又惊又喜，如果有一种新的 `SortedSet` 实现能够将 B 树的性能再提升哪怕 50%，我都会觉得大为震惊。
 
 ## 实现常数时间的插入
 
 虽然可能在保持 `BTree3` 满足 `SortedSet` 所有要求的同时，大幅提升性能可能是难以做到的，不过如果我们作点弊的话，我们总归是能让它变得更快的。
 
 比如说，下面代码中的 `SillySet` 在语法上实现了 `SortedSet` 协议的要求，而且拥有一个 $O(1)$ 时间复杂度的 `insert` 方法。它在上面的 `insert` 性能测试中不费吹灰之力地就能和 `Array.sort` 一较高下：
*/
struct SillySet<Element: Hashable & Comparable>: SortedSet, RandomAccessCollection {
    typealias Indices = CountableRange<Int>

    class Storage {
        var v: [Element]
        var s: Set<Element>
        var extras: Set<Element> = []
    
        init(_ v: [Element]) { 
            self.v = v
            self.s = Set(v) 
        }
    
        func commit() {
            guard !extras.isEmpty else { return }
            s.formUnion(extras)
            v += extras
            v.sort()
            extras = []
        }
    }

    private var storage = Storage([])
    
    var startIndex: Int { return 0 }
    
    var endIndex: Int { return storage.s.count + storage.extras.count }
    
    // 复杂度：`O(n*log(n))`，此处 `n` 是从上一次 `subscript` 被调用以来插入被调用的次数。
    subscript(i: Int) -> Element {
        storage.commit()
        return storage.v[i]
    }
    
    // 复杂度：O(1)
    func contains(_ element: Element) -> Bool {
        return storage.s.contains(element) || storage.extras.contains(element)
    }
    
    // 复杂度：除非存储是共享的，否则为 O(1)
    mutating func insert(_ element: Element) -> (inserted: Bool, memberAfterInsert: Element) {
        if !isKnownUniquelyReferenced(&storage) {
            storage = Storage(storage.v)
        }
        if let i = storage.s.index(of: element) { return (false, storage.s[i]) }
        return storage.extras.insert(element)
    }
}
/*:
 当然了，这里的代码有很多问题：比如，要求 `Element` 是可哈希的，违反了 `Collection` 的下标要求，使用 $O(n \log n)$ 这样慢到令人惊讶的时间复杂度等。但是我认为最让人恼火的是，`SillySet` 的索引下标带有副作用，它将会改变底层存储，这破坏了 Swift 中我们关于值语义含义的假设。(举个例子，在线程中传递 `SillySet` 是很危险的，即使是只读的并行访问也会导致数据发生竞争。)
 
 这个特定的例子也许看起来实在是很蠢，不过通过将连续插入操作的值收集起来放到一个单独的缓冲区里，以此推迟实际操作的执行时机这个想法本身还是值得赞赏的。将一系列元素用循环的方式一个个插入到有序集合中，这是一种效率很低的做法。我们可以先将这些元素放到单独的缓冲区中排序，然后在线性时间内用一个特殊的[批量加载初始化方法][bulk]将该缓冲区转为一棵 B 树，这么做的话会快很多。
 
 [bulk]: https://github.com/lorentey/BTree/blob/v4.0.2/Sources/BTreeBuilder.swift
 
 我们不去关心一个有序集合在插入时的中间状态是否满足要求，因为我们绝不会去使用一个只加载到一半的集合，批量加载之所以可行，正是利用了这一点，我们也因此得到了性能的提升。
 
 辨识这类优化机会是十分重要的，它让我们能**暂时**脱离一般的限制，而且这会为我们带来在被限制时所不可能得到的大幅度的性能提升。
 
 ## 再会
 
 我在写这本书的时候获得了很多乐趣，所以我希望您也能喜欢这本书！这一路走来，我学会了不少在 Swift 中实现集合类型的方法，希望您也掌握了一些新的技巧。
 
 在整本书中，我们探索了数种方式，为了解决构建有序集合这一特定问题，我们集中精力对解决方案进行了性能测试，并不断找寻能够改善性能的方式。
 
 不过，这些实现方式都还不完整，我们的代码也并没有真正好到可以在实际产品中使用。为了保持整本书**相对**较短，我们走了一些捷径，而有些捷径并不适合使用在实际项目之中。
 
 就算是我们的 `SortedSet` 协议，也是被简化至最小的：我们去掉了 `SetAlgebra` 中大部分的方法。比如，我们从来没有讨论过如何实现一个 `remove` 操作。可能你会觉得意外，但事实就是，从一个已经平衡的树中移除元素往往要比添加元素困难得多。(你可以自己试试看！)
 
 我们没有花时间去检查那些我们可以通过平衡搜索树构建的其他数据类型。树结构的有序映射 (map)、列表 (list) ，以及像是多重集合 (multiset) 和多重映射 (multimap) ，都是和有序集合一样重要的数据结构；仔细研究如何改写我们的代码来实现它们会是一件非常有意思的事情。
 
 我们也没有对这些实现方式应当如何被测试做出解释。省略这部分是一个非常艰难的决定，因为我们写了不少取巧的代码，有时候我们甚至使用了不安全的构造方式，最微小的错误都可能会酿成可怕的内存错误，造成让人抓狂的调试工作。
 
 测试实在是太重要了；特别是单元测试，它能为集合类型的正确性提供安全保障，也几乎是进行所有优化工作的先决条件。数据结构自身的特点使它非常适合进行单元测试：它们的操作所接受的输入很容易生成，产生的输出也都是定义良好、易于验证的。使用像是 [SwiftCheck] 这样强大的工具，可以很容易地为项目提供完整的测试覆盖。
 
 [SwiftCheck]: https://github.com/typelift/SwiftCheck
 
 不过，测试写时复制的实现并不是一件简单的事。即使我们不够仔细，不小心在调用 `isKnownUniquelyReferenced` 之前创建了强引用，我们的代码依然会给出正确的结果，只不过会比我们所期待的慢上许多。我们通常不会在单元测试中检查这样的性能问题，所以我们需要用特殊的手段衡量代码的性能，从而用简单的方法来捕获这类问题。
 
 相反，如果忘记了在改变共享存储前对它进行复制，我们的代码将会影响到那些持有未改变的复制的变量。这样的操作所破坏的值并不一定会明显地表现在操作的输入或者输出上，在原因和结果之间**有一定距离的非预期行为**是很难被追踪的。就算是我们拥有 100% 的测试覆盖率，一般的输入/输出也不一定会去检测这种情况。因此为了捕获这种错误，我们需要专门为这种情况编写单元测试。
 
 我们简单提到过，通过向一棵搜索树的节点中添加属性来存储节点下的元素个数，我们就可以在 $O(\log n)$ 的时间内寻找到树中第 $i$ 个最小或者最大的元素。实际上这个技巧可以被一般化：对包含任意尺度的元素的搜索树，对其进行信息扩充，可以加速所有的关联二分操作。在算法问题中，扩充一直是一个秘密武器：它让我们可以轻易地解决很多看上去复杂的问题。我们这里没有时间对如何实现扩充树以及如何使用它们来解决问题做更详细的解释了。
 
 现在是这本书该完结的时候了，针对我们的问题，我们已经找到了看起来最好的数据结构，此外，我们已经准备好着手将它构建成一个完整的、产品级的解决方案了。从各种角度来说，这都不会是一件简单的工作：我们已经研究过不少操作了，但是仍然需要继续构建和测试更多的代码，并为它们编写文档！
 
 如果你很喜欢本书，并想要亲自动手尝试将集合类型的代码优化为产品可用的质量，可以看看我在 GitHub 上开源的 [`BTree` 项目][BTree-GitHub]。在写作时，这个项目最新的版本中甚至还没有包含我们原先在 B 树代码中所做的某些优化，更不用说第七章里的一些进阶内容了。这个项目还有很大的改进空间，我们也随时欢迎您作出贡献。
 
 [BTree-GitHub]: https://github.com/lorentey/BTree

 [Next page](@next)
*/